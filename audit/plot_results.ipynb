{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# NOTE: Change `<PATH_TO_TEX>` to an appropriate texlive installation\n",
    "# add latex \n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + '<PATH_TO_TEX>/bin/x86_64-linux'\n",
    "\n",
    "img_dir = 'results/cv_images/'\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "# graphing\n",
    "plt.rcParams.update({\n",
    "    'font.size': 13,\n",
    "    'text.usetex': True,\n",
    "    'text.latex.preamble': r'\\usepackage{libertine}\\usepackage[libertine]{newtxmath} \\usepackage{sfmath}',\n",
    "    'font.family': 'sans-serif',\n",
    "})\n",
    "palette = plt.cm.jet(np.linspace(0,1,21))\n",
    "all_colors = [matplotlib.colors.to_hex(color, keep_alpha=True) for color in palette]\n",
    "\n",
    "markers = ['s', '*', 'o', '^', 'p', '1', 'P', 'X']\n",
    "colors = [all_colors[-1], all_colors[5],  all_colors[-3], all_colors[7], all_colors[15]]\n",
    "\n",
    "model_names = ['DSynthPB', 'NIST_MST', 'DPWGAN', 'DPartPB', 'MST', 'DPWGANCity']\n",
    "model_name_labels = ['PrivBayes (DS)', 'MST (NIST)', 'DPWGAN (NIST)', 'PrivBayes (Hazy)', 'MST (Smartnoise)', 'DPWGAN (Synthcity)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot vertical bars\n",
    "def plot_barv(ax, resultss, labels, upper_bound=None, title=None, xticklabels=None, capsize=3):\n",
    "    if xticklabels is None:\n",
    "        xticklabels = model_name_labels\n",
    "    xticks = np.arange(len(xticklabels))\n",
    "        \n",
    "    # sort all results\n",
    "    custom_dict = {model_name: i for i, model_name in enumerate(model_names)} \n",
    "    sorted_resultss = []\n",
    "    for results in resultss:\n",
    "        results = results.sort_values(by=['theor_eps'])\n",
    "        sorted_resultss.append(results.sort_values(by=['model'], key=lambda x: x.map(custom_dict)))\n",
    "\n",
    "    if len(resultss) == 1:\n",
    "        width = 0.4\n",
    "        curr_colors = [colors[4]]\n",
    "    elif len(resultss) == 2:\n",
    "        width = 0.4\n",
    "        curr_colors = [colors[4], colors[1]]\n",
    "    elif len(resultss) == 3:\n",
    "        width = 0.25\n",
    "        curr_colors = [colors[4], colors[1], all_colors[-1]]\n",
    "    elif len(resultss) == 4:\n",
    "        width = 0.2\n",
    "        curr_colors = [colors[4], colors[1], all_colors[-1], colors[3]]\n",
    "    elif len(resultss) == 5:\n",
    "        width = 0.15\n",
    "        curr_colors = [all_colors[15], all_colors[5],  all_colors[-3], all_colors[7], all_colors[-1]]\n",
    "    elif len(resultss) == 6:\n",
    "        width = 0.125\n",
    "        curr_colors = [all_colors[15], all_colors[5],  all_colors[-3], all_colors[7], all_colors[-1], all_colors[16]]\n",
    "    \n",
    "    if len(resultss) % 2 == 0:\n",
    "        # even\n",
    "        seed_pos = [(i + 0.5) * width for i in range(len(resultss) // 2)]\n",
    "        positions = [-pos for pos in reversed(seed_pos)] + seed_pos\n",
    "    else:\n",
    "        # odd\n",
    "        seed_pos = [i * width for i in range(len(resultss) // 2 + 1)]\n",
    "        positions = [-pos for pos in reversed(seed_pos[1:])] + seed_pos\n",
    "\n",
    "    offset = 0.25\n",
    "\n",
    "    for pos, results, color, label in zip(positions, sorted_resultss, curr_colors, labels):\n",
    "        ax.bar(xticks + pos, results['emp_eps_mean'] + offset, width=width, bottom=-offset, zorder=2, color=color, label=label, yerr=results['emp_eps_std'], capsize=capsize)\n",
    "\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels([label.replace(' ', '\\n') for label in xticklabels])\n",
    "\n",
    "    ax.set_ylim(-offset, 30)\n",
    "    ax.set_ylabel('Empirical $\\\\varepsilon_{emp}$')\n",
    "    ax.grid(color='#DCDCDC', linestyle='-', linewidth=1, zorder=0)\n",
    "\n",
    "    if upper_bound is not None:\n",
    "        x_l, x_r, _, _ = ax.axis()\n",
    "        ax.plot([x_l, x_r], [upper_bound, upper_bound], linestyle='--', color='red', label='Theoretical $\\\\varepsilon$')\n",
    "        ax.set_xlim(x_l, x_r)\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot horizontal bars\n",
    "def plot_barh(ax, resultss, labels, upper_bound=None, title=None, capsize=3):\n",
    "    # sort all results\n",
    "    custom_dict = {model_name: i for i, model_name in enumerate(model_names)} \n",
    "    sorted_resultss = []\n",
    "    for results in resultss:\n",
    "        results = results.sort_values(by=['theor_eps'])\n",
    "        sorted_resultss.append(results.sort_values(by=['model'], key=lambda x: x.map(custom_dict)))\n",
    "\n",
    "    n_models = len(model_names)\n",
    "\n",
    "    if len(resultss) == 2:\n",
    "        positions = [-0.2, +0.2]\n",
    "        height = 0.4\n",
    "        curr_colors = [colors[4], colors[1]]\n",
    "\n",
    "    offset = 0.25\n",
    "\n",
    "    for pos, results, color, label in zip(positions, sorted_resultss, curr_colors, labels):\n",
    "        ax.barh(np.arange(n_models) + pos, results['emp_eps_mean'] + offset, height=height, left=-offset, zorder=2, color=color, label=label, xerr=results['emp_eps_std'], capsize=capsize)\n",
    "\n",
    "    ax.set_yticks(np.arange(n_models))\n",
    "    ax.set_yticklabels([label.replace(' ', '\\n') for label in model_name_labels])\n",
    "\n",
    "    ax.set_xlim(-offset, 30)\n",
    "    ax.set_xlabel('Empirical $\\\\varepsilon_{emp}$')\n",
    "    ax.grid(color='#DCDCDC', linestyle='-', linewidth=1, zorder=0)\n",
    "\n",
    "    if upper_bound is not None:\n",
    "        _, _, y_l, y_r = ax.axis()\n",
    "        ax.plot([upper_bound, upper_bound], [y_l, y_r], linestyle='--', color='red', label='Theoretical $\\\\varepsilon$')\n",
    "        ax.set_ylim(y_l, y_r)\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing empirical epsilons of Querybased vs DCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(f'results/cv_shuffle_results/qb_vs_dcr/results_agg.csv')\n",
    "for i, eps in enumerate([1.0, 4.0]):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.subplots_adjust(wspace=0.1)\n",
    "    for data_name, ax in zip(['Adult', 'Fire'], axs.flat):\n",
    "        resultss = [\n",
    "            results[(results['attack_type'] == 'bb_querybased') & (results['data_name'] == data_name.lower()) & (results['theor_eps'] == eps)],\n",
    "            results[(results['attack_type'] == 'bb_dcr') & (results['data_name'] == data_name.lower()) & (results['theor_eps'] == eps)]\n",
    "        ]\n",
    "        plot_barh(ax, resultss, ['Querybased', 'DCR'], upper_bound=eps, title=data_name)\n",
    "\n",
    "        ax.label_outer()\n",
    "\n",
    "    if i == 0:\n",
    "        h,l = axs.flat[1].get_legend_handles_labels()\n",
    "        fig.legend(h, l, loc='upper center', ncol=len(h), bbox_to_anchor=(0.5, 1.05))\n",
    "\n",
    "    fig.set_size_inches(10, 5)\n",
    "    fig.savefig(f'{img_dir}/qb_vs_dcr_eps{eps}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "scoresss = dill.load(open('results/qb_vs_dcr.dill', 'rb'))\n",
    "\n",
    "for i, (attack_type, attack_type_name) in enumerate(zip(['querybased', 'dcr'], ['Querybased', 'DCR'])):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.subplots_adjust(wspace=0.1)\n",
    "    for data_name, data_title, ax in zip(['adult', 'fire'], ['Adult', 'FIRE'], axs.flat):\n",
    "        scoress = scoresss[data_name][attack_type]\n",
    "\n",
    "        scores_in = scoress[scoress[:, 1] == 1][-2000:, 0]\n",
    "        scores_out = scoress[scoress[:, 1] == 0][-2000:, 0]\n",
    "\n",
    "        if attack_type == 'dcr':\n",
    "            bins = np.unique(scores_in).tolist() + [0]\n",
    "        else:\n",
    "            bins = (np.arange(11) / 10).tolist()\n",
    "\n",
    "        ax.hist(scores_out, alpha=0.5, color=colors[1], label='$D\\,\\'$', bins=bins)\n",
    "        ax.hist(scores_in, alpha=0.5, color=colors[4], label='$D$', bins=bins)\n",
    "\n",
    "        ax.set_ylim(0, 2000)\n",
    "\n",
    "        ax.set_title(data_title)\n",
    "        \n",
    "        ax.set_xlabel('Score')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        \n",
    "        ax.label_outer()\n",
    "\n",
    "    fig.set_size_inches(10, 5)\n",
    "\n",
    "    if i == 0:\n",
    "        h,l = axs.flat[1].get_legend_handles_labels()\n",
    "        fig.legend(h, l, loc='upper center', ncol=len(h), bbox_to_anchor=(0.5, 1.05))\n",
    "\n",
    "    fig.savefig(f'{img_dir}/qb_vs_dcr_scores_{attack_type}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing empirical epsilons of worst-case datasets (black-box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "results = pd.read_csv(f'results/cv_shuffle_results/test_worst_case/results_agg.csv')\n",
    "resultss = [results[(results['dataset_type'] == dataset_type) & (results['attack_type'] == 'bb_querybased')] for dataset_type in ['worstcase', 'worstcase_narrow', 'worstcase_repeat', 'worstcase_narrow_repeat']]\n",
    "plot_barv(ax, resultss, ['small', 'small+narrow', 'small+repeat', 'small+narrow+repeat'], upper_bound=4.0)\n",
    "\n",
    "ax.set_ylim(-0.25, 5)\n",
    "\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "fig.legend(h, l, loc='upper center', ncol=3, bbox_to_anchor=(0.5, 1.05))\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "fig.savefig(f'{img_dir}/compare_worstcase_datasets.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing white-box vs black-box attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "results = pd.read_csv(f'results/cv_shuffle_results/test_worst_case/results_agg.csv')\n",
    "results = results[\n",
    "    ((results['model'] == 'DSynthPB') & (results['dataset_type'] == 'worstcase_narrow')) |\n",
    "    ((results['model'] == 'DPartPB') & (results['dataset_type'] == 'worstcase_narrow_repeat')) | \n",
    "    ((results['model'].isin(['NIST_MST', 'MST', 'DPWGAN', 'DPWGANCity'])) & (results['dataset_type'] == 'worstcase_repeat'))\n",
    "]\n",
    "resultss = [results[(results['attack_type'] == attack_type)] for attack_type in ['bb_querybased', 'wb']]\n",
    "plot_barv(ax, resultss, ['Black-box', 'White-box'], upper_bound=4.0)\n",
    "\n",
    "ax.set_ylim(-0.25, 6)\n",
    "\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "fig.legend(h, l, loc='upper center', ncol=3, bbox_to_anchor=(0.5, 1))\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "fig.savefig(f'{img_dir}/bb_vs_wb_worstcase.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting empirical epsilons for various theoretical $\\varepsilon$ s of worst-case datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "title = '(Implementation-specific) Worst-case dataset'\n",
    "\n",
    "results = pd.read_csv(f'results/cv_shuffle_results/worst_case_wb/results_agg.csv')\n",
    "\n",
    "resultss = [results[(results['model'] == model_name)] for model_name in model_names[:-1]] # exclude DPWGAN (Synthcity)\n",
    "plot_barv(ax, resultss, model_name_labels[:-1], upper_bound=None, title=title, xticklabels=['$1.0$', '$2.0$', '$4.0$', '$10.0$'])\n",
    "\n",
    "epses = results['theor_eps'].unique()\n",
    "for i, eps in enumerate(epses):\n",
    "    ax.plot([i - 0.45, i + 0.45], [eps, eps], color='red', linestyle='--', label='Theoretical $\\\\varepsilon$' if i == 0 else None)\n",
    "\n",
    "ax.set_xlabel('Theoretical $\\\\varepsilon$')\n",
    "ax.set_ylim(-0.25, 11.0)\n",
    "\n",
    "ax.set_yticks(np.arange(12))\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "fig.savefig(f'{img_dir}/worstcase_audit_multeps.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting white-box vs active white-box attack for DPWGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "results = pd.read_csv(f'results/cv_shuffle_results/active_wb/results_agg.csv')\n",
    "\n",
    "resultss = [results[(results['attack_type'] == attack_type)] for attack_type in ['bb_querybased', 'wb', 'active_wb']]\n",
    "plot_barv(ax, resultss, ['Black-box', 'White-box', 'Active White-box'], upper_bound=None, title='DPWGAN (NIST)', xticklabels=['$1.0$', '$2.0$', '$4.0$', '$10.0$'])\n",
    "\n",
    "epses = results['theor_eps'].unique()\n",
    "for i, eps in enumerate(epses):\n",
    "    ax.plot([i - 0.4, i + 0.4], [eps, eps], color='red', linestyle='--', label='Theoretical $\\\\varepsilon$' if i == 0 else None)\n",
    "\n",
    "ax.set_xlabel('Theoretical $\\\\varepsilon$')\n",
    "ax.set_ylim(-0.25, 11.0)\n",
    "ax.set_yticks(np.arange(12))\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "fig.savefig(f'{img_dir}/wb_vs_active_wb.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSynthesizer v0.1.4\n",
    "- wrong noise scale bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate maximum epsilon limit\n",
    "from dp_utils import compute_eps_lower_single\n",
    "from privacy_estimates import AttackResults\n",
    "\n",
    "n_obs = 2000\n",
    "compute_eps_lower_single(AttackResults(FP=0, FN=0, TP=n_obs//2, TN=n_obs//2), 0.1, 0, method='cp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "results = pd.read_csv(f'results/cv_shuffle_results/ds_0.1.4/results_agg.csv')\n",
    "\n",
    "resultss = [results[results['model'] == model_name] for model_name in ['DSynthPB']]\n",
    "plot_barv(ax, resultss, ['White-box'], upper_bound=None, title='PrivBayes (DS) v0.1.4', xticklabels=['$1.0$', '$2.0$', '$4.0$', '$10.0$'])\n",
    "\n",
    "epses = results['theor_eps'].unique()\n",
    "for i, eps in enumerate(epses):\n",
    "    ax.plot([i - 0.4, i + 0.4], [eps, eps], color='red', linestyle='--', label='Theoretical $\\\\varepsilon$' if i == 0 else None)\n",
    "\n",
    "x_l, x_r, _, _ = ax.axis()\n",
    "ax.plot([x_l, x_r], [5.60, 5.60], linestyle='-.', color='black', label='Maximum auditable $\\\\varepsilon$')\n",
    "ax.set_xlim(x_l, x_r)\n",
    "\n",
    "ax.set_xlabel('Theoretical $\\\\varepsilon$')\n",
    "ax.set_ylim(-0.25, 10.0)\n",
    "ax.set_yticks(np.arange(12))\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "fig.savefig(f'{img_dir}/ds_0.1.4.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPWGAN\n",
    "- early stopping bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "results = pd.read_csv(f'results/cv_shuffle_results/dpwgan_bug/results_agg.csv')\n",
    "\n",
    "resultss = [results[(results['model'] == 'DPWGAN') & (results['attack_type'] == attack_type)] for attack_type in ['bb_querybased', 'wb', 'active_wb']]\n",
    "plot_barv(ax, resultss, ['Black-box', 'White-box', 'Active White-box'], upper_bound=None, title='DPWGAN (NIST)', xticklabels=['$0.1$', '$0.4$', '$1.0$', '$4.0$'])\n",
    "\n",
    "epses = results['theor_eps'].unique()\n",
    "for i, eps in enumerate(epses):\n",
    "    ax.plot([i - 0.4, i + 0.4], [eps, eps], color='red', linestyle='--', label='Theoretical $\\\\varepsilon$' if i == 0 else None)\n",
    "\n",
    "ax.set_xlabel('Theoretical $\\\\varepsilon$')\n",
    "ax.set_ylim(-0.25, 45.0)\n",
    "ax.set_yticks([0, 5, 10, 15, 20, 25, 30, 35, 40, 45])\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "fig.savefig(f'{img_dir}/dpwgan_bug.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PrivBayes White-box Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "results = pd.read_csv(f'results/cv_shuffle_results/feat_types_epses/results_agg.csv')\n",
    "\n",
    "for model_name, model_name_label, ax in zip(['DPartPB', 'DSynthPB'], ['PrivBayes (DS)', 'PrivBayes (Hazy)'], axs.flat):\n",
    "    resultss = [results[(results['model'] == model_name) & (results['attack_type'] == attack_type)] for attack_type in ['wb_vals', 'wb_errors+sum']]\n",
    "    plot_barv(ax, resultss, ['$\\mathcal{F}_{naive}$', '$\\mathcal{F}_{error}$'], upper_bound=None, title=model_name_label, xticklabels=['$1.0$', '$2.0$', '$4.0$', '$10.0$'])\n",
    "\n",
    "    ax.set_xlabel('Theoretical $\\\\varepsilon$')\n",
    "    ax.set_ylim(-0.25, 10.0)\n",
    "    ax.set_yticks(np.arange(11))\n",
    "\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "fig.legend(h, l, loc='upper center', ncol=3, bbox_to_anchor=(0.5, 1.05))\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "fig.savefig(f'{img_dir}/feat_types_privbayes.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MST White-box Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "results = pd.read_csv(f'results/cv_shuffle_results/feat_types_epses/results_agg.csv')\n",
    "\n",
    "for model_name, model_name_label, ax in zip(['NIST_MST', 'MST'], ['MST (NIST)', 'MST (Smartnoise)'], axs.flat):\n",
    "    resultss = [results[(results['model'] == model_name) & (results['attack_type'] == attack_type)] for attack_type in ['wb_vals', 'wb_errors+sum']]\n",
    "    plot_barv(ax, resultss, ['$\\mathcal{F}_{naive}$', '$\\mathcal{F}_{error}$'], upper_bound=None, title=model_name_label, xticklabels=['$1.0$', '$2.0$', '$4.0$', '$10.0$'])\n",
    "\n",
    "    ax.set_xlabel('Theoretical $\\\\varepsilon$')\n",
    "    ax.set_ylim(-0.25, 10.0)\n",
    "    ax.set_yticks(np.arange(11))\n",
    "\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "fig.legend(h, l, loc='upper center', ncol=3, bbox_to_anchor=(0.5, 1.05))\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "fig.savefig(f'{img_dir}/feat_types_mst.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare worst-case datasets\n",
    "- white-box attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "results = pd.read_csv(f'results/cv_shuffle_results/test_worst_case/results_agg.csv')\n",
    "resultss = [results[(results['dataset_type'] == dataset_type) & (results['attack_type'] == 'wb')] for dataset_type in ['worstcase', 'worstcase_narrow', 'worstcase_repeat', 'worstcase_narrow_repeat']]\n",
    "plot_barv(ax, resultss, ['small', 'small+narrow', 'small+repeat', 'small+narrow+repeat'], upper_bound=4.0)\n",
    "\n",
    "ax.set_ylim(-0.25, 6)\n",
    "\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "fig.legend(h, l, loc='upper center', ncol=3, bbox_to_anchor=(0.5, 1.05))\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "fig.savefig(f'{img_dir}/compare_worstcase_datasets_wb.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth-attack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
